{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "318283be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'facts': [{'text': 'Bob Ross',\n",
       "   'tag': 'PERSON',\n",
       "   'tokens': [{'text': 'Bob', 'offset': 0}, {'text': 'Ross', 'offset': 4}]},\n",
       "  {'text': 'Florida',\n",
       "   'tag': 'LOCATION',\n",
       "   'tokens': [{'text': 'Florida', 'offset': 18}]}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from natasha import (\n",
    "    MorphVocab,\n",
    "    NewsEmbedding,\n",
    "    NewsNERTagger,\n",
    "    Segmenter,\n",
    "    Doc,\n",
    "\n",
    "    NamesExtractor,\n",
    "    DatesExtractor,\n",
    "    MoneyExtractor,\n",
    "    AddrExtractor\n",
    ")\n",
    "from natasha.doc import DocSpan\n",
    "\n",
    "\n",
    "segmenter = Segmenter()\n",
    "emb = NewsEmbedding()\n",
    "ner_tagger = NewsNERTagger(emb)\n",
    "morph_vocab = MorphVocab()\n",
    "\n",
    "names_extractor = NamesExtractor(morph_vocab)\n",
    "dates_extractor = DatesExtractor(morph_vocab)\n",
    "money_extractor = MoneyExtractor(morph_vocab)\n",
    "addr_extractor = AddrExtractor(morph_vocab)\n",
    "\n",
    "\n",
    "def get_full_tag(tag):\n",
    "    \"\"\"\n",
    "    Function returning full version of received tag.\n",
    "    Example: LOC - LOCATION, PER - PERSON etc.\n",
    "    \"\"\"\n",
    "\n",
    "    replacements = {\n",
    "        \"LOC\":\"LOCATION\",\n",
    "        \"PER\":\"PERSON\",\n",
    "        \"ORG\":\"ORGANISATION\",\n",
    "    }\n",
    "\n",
    "    new_tag = tag\n",
    "\n",
    "    for old, new in replacements.items():\n",
    "        new_tag = new_tag.replace(old, new)\n",
    "\n",
    "    return new_tag\n",
    "\n",
    "\n",
    "def get_fact_from_span(span):\n",
    "    \"\"\"Function transforms span from natasha NER to a service result format.\"\"\"\n",
    "\n",
    "    text = span.text\n",
    "    tag = span.type\n",
    "    tokens = []\n",
    "\n",
    "    for token in span.tokens:\n",
    "        current_token = {\n",
    "            \"text\": token.text,\n",
    "            \"offset\": token.start\n",
    "        }\n",
    "        tokens.append(current_token)\n",
    "\n",
    "    fact = {\n",
    "        \"text\": text,\n",
    "        \"tag\": get_full_tag(tag),\n",
    "        \"tokens\": tokens\n",
    "    }\n",
    "\n",
    "    return fact\n",
    "\n",
    "\n",
    "def format_spans(spans):\n",
    "    \"\"\"Function formats spans from natasha NER to a service result format.\"\"\"\n",
    "    \n",
    "    facts = []\n",
    "    \n",
    "    for span in spans:\n",
    "        fact = get_fact_from_span(span)\n",
    "        facts.append(fact)\n",
    "        \n",
    "    return facts\n",
    "\n",
    "\n",
    "def form_result(facts):\n",
    "    \"\"\"Function forms service result.\"\"\"\n",
    "    \n",
    "    result = {\n",
    "        \"facts\": facts\n",
    "    }\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def tag_entities(text, extractor):\n",
    "    \"\"\"Function extracts entities according to given extractor.\n",
    "    Natasha's lib extractors are expected:\n",
    "        DatesExtractor,\n",
    "        MoneyExtractor\n",
    "    \"\"\"\n",
    "    \n",
    "    def _adjust_tokens(tokens, match):\n",
    "        \"\"\"Function makes certain entity tokens spans fitting given text.\"\"\"\n",
    "        \n",
    "        adj_tokens = []\n",
    "        \n",
    "        for token in tokens:\n",
    "            token.start = match.start + token.start\n",
    "            token.stop = match.start + token.stop\n",
    "            adj_tokens.append(token)\n",
    "            \n",
    "        return adj_tokens \n",
    "    \n",
    "    tags = {\n",
    "        \"NamesExtractor\": \"NAME\",\n",
    "        \"DatesExtractor\": \"DATE\",\n",
    "        \"MoneyExtractor\": \"MONEY\",\n",
    "        \"AddrExtractor\": \"ADDRESS\"\n",
    "    }\n",
    "    \n",
    "    #  Getting matches.\n",
    "    matches = list(extractor(text))\n",
    "    spans = []\n",
    "    \n",
    "    for match in matches:        \n",
    "        span_text = text[match.start:match.stop] #  Getting whole money match span text(not tokenized).\n",
    "        tag = tags[extractor.__class__.__name__] #  Setting tag name\n",
    "        \n",
    "        #  Tokenizing text in order to get tokens of entity.\n",
    "        ndoc = Doc(span_text)\n",
    "        ndoc.segment(segmenter)\n",
    "        \n",
    "        tokens = _adjust_tokens(ndoc.tokens, match)\n",
    "        \n",
    "        #  Creating money span class in a similar format to natasha's other tags format(LOC, ORG, PER).\n",
    "        #  DocSpan class is imported from natasha lib.\n",
    "        span = DocSpan(\n",
    "            match.start,\n",
    "            match.stop,\n",
    "            tag,\n",
    "            span_text,\n",
    "            tokens\n",
    "        )\n",
    "\n",
    "        spans.append(span)\n",
    "    \n",
    "    return spans\n",
    "\n",
    "\n",
    "def ner_text(text):\n",
    "    \"\"\"Main function of NER module. Prepares result and goes through all steps of named entities extraction.\"\"\"\n",
    "    \n",
    "    ndoc = Doc(text)\n",
    "    \n",
    "    ndoc.segment(segmenter)\n",
    "    ndoc.tag_ner(ner_tagger)\n",
    "    \n",
    "    money_spans = tag_entities(text, money_extractor)\n",
    "    dates_spans = tag_entities(text, dates_extractor)\n",
    "\n",
    "    entities = money_spans + ndoc.spans + dates_spans\n",
    "    \n",
    "    facts = format_spans(entities)\n",
    "    \n",
    "    result = form_result(facts)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "#text = \"Россия. 03.01.2005 Максим Шутов\"\n",
    "text = \"Bob Ross lived in Florida.\"\n",
    "ner_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84ef68b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Doc(text='Россия. 03.01.2005 Максим Шутов', tokens=[...], sents=[...])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[DocSent(stop=7, text='Россия.', tokens=[...]),\n",
       " DocSent(start=8, stop=31, text='03.01.2005 Максим Шутов', tokens=[...])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[DocToken(stop=6, text='Россия'),\n",
       " DocToken(start=6, stop=7, text='.'),\n",
       " DocToken(start=8, stop=18, text='03.01.2005'),\n",
       " DocToken(start=19, stop=25, text='Максим'),\n",
       " DocToken(start=26, stop=31, text='Шутов')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndoc = Doc(text)\n",
    "\n",
    "ndoc.segment(segmenter)\n",
    "\n",
    "display(ndoc)\n",
    "display(ndoc.sents[:100])\n",
    "display(ndoc.tokens[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "464955d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocSpan(stop=6, type='LOC', text='Россия', tokens=[...]),\n",
       " DocSpan(start=19, stop=31, type='PER', text='Максим Шутов', tokens=[...])]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ndoc.tag_ner(ner_tagger)\n",
    "\n",
    "display(ndoc.spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57afc2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DocToken(stop=6, text='Россия')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ndoc.spans[0].tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c44b46f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "money_spans = tag_entities(text, money_extractor)\n",
    "\n",
    "money_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074f729f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates_spans = tag_entities(text, dates_extractor)\n",
    "\n",
    "dates_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e60540b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "entities = money_spans + ndoc.spans + dates_spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90235a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': 'Россия',\n",
       "  'tag': 'LOCATION',\n",
       "  'tokens': [{'text': 'Россия', 'offset': 0}]}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "facts = format_spans(entities)\n",
    "\n",
    "facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fef1c93d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'facts': [{'text': 'Россия',\n",
       "   'tag': 'LOCATION',\n",
       "   'tokens': [{'text': 'Россия', 'offset': 0}]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = form_result(facts)\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cbaf3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c6d38ee7-7982-40a0-8369-7ac4713f2ab2'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "str(uuid.uuid4())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb58ea7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
